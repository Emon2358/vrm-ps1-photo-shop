<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>nihonkokumin_VJ_V3</title>
    <link rel="icon" href="data:,">

    <style>
        /* --- UNDERGROUND STYLING --- */
        body, html {
            margin: 0; padding: 0; width: 100%; height: 100%;
            background-color: #000; overflow: hidden;
            font-family: 'Courier New', Courier, monospace;
        }

        /* 背景の砂嵐ノイズ (アバターが消えた時に見える) */
        .static-noise {
            position: fixed; top: 0; left: 0; width: 100%; height: 100%;
            opacity: 0.15; z-index: 0; pointer-events: none;
            background: url('https://media.giphy.com/media/oEI9uBYSzLpBK/giphy.gif');
            background-size: cover;
        }

        #canvas {
            display: block; position: absolute; top: 0; left: 0; z-index: 1;
        }

        /* UI Overlay */
        #ui-layer {
            position: absolute; top: 0; left: 0; width: 100%; height: 100%;
            z-index: 10; pointer-events: none;
            padding: 20px; box-sizing: border-box;
            color: #00ffcc; /* サイバーシアン */
            text-shadow: 2px 2px 0px #000;
        }

        h1 { 
            font-size: 1.5rem; margin: 0; letter-spacing: 3px; 
            border-bottom: 2px solid #00ffcc; display: inline-block; background: #000;
        }
        p { font-size: 0.8rem; margin: 5px 0; background: #000; display: inline-block;}

        /* Controls */
        .controls {
            margin-top: 20px; pointer-events: auto; display: flex; gap: 10px; flex-wrap: wrap;
        }

        .cyber-btn {
            padding: 10px 20px; border: 1px solid #00ffcc; background: #000;
            color: #00ffcc; cursor: pointer; font-weight: bold; font-family: inherit;
            transition: 0.1s; text-transform: uppercase;
            min-width: 120px; text-align: center;
        }
        .cyber-btn:hover { background: #00ffcc; color: #000; }
        .cyber-btn.active { background: #00ffcc; color: #fff; box-shadow: 0 0 15px #00ffcc; }
        .cyber-btn:disabled { opacity: 0.3; cursor: not-allowed; border-color: #555; color: #555; }

        /* 録画ボタンは赤くする */
        #btn-rec { border-color: #ff004c; color: #ff004c; }
        #btn-rec:hover { background: #ff004c; color: #000; }
        #btn-rec.active { background: #ff004c; color: #fff; box-shadow: 0 0 15px #ff004c; }

        #status-log {
            position: absolute; bottom: 20px; left: 20px; 
            font-size: 0.7rem; color: #fff; white-space: pre;
        }

        /* 録画中インジケーター */
        #rec-indicator {
            display: none; position: absolute; top: 20px; right: 20px;
            color: red; font-weight: bold; animation: blink 1s infinite;
            background: #000; padding: 5px; border: 1px solid red;
        }
        @keyframes blink { 50% { opacity: 0; } }

        input[type="file"] { display: none; }
    </style>

    <script type="importmap">
    {
        "imports": {
            "three": "https://unpkg.com/three@0.160.0/build/three.module.js",
            "three/addons/": "https://unpkg.com/three@0.160.0/examples/jsm/",
            "@pixiv/three-vrm": "https://unpkg.com/@pixiv/three-vrm@2.1.0/lib/three-vrm.module.js"
        }
    }
    </script>
</head>
<body>
    <div class="static-noise"></div>

    <div id="ui-layer">
        <h1>V3.0: AUDIO_SYNC_SYSTEM</h1>
        <div>
            <p>>> MODE: FILE_PLAYBACK (LOOP)</p><br>
            <p>>> PROTOCOL: DECAY</p>
        </div>

        <div class="controls">
            <input type="file" id="vrm-input" accept=".vrm">
            <label for="vrm-input" class="cyber-btn">1. LOAD VRM</label>
            
            <input type="file" id="audio-input" accept=".mp3, .wav, .flac, .m4a">
            <label for="audio-input" class="cyber-btn">2. LOAD AUDIO</label>

            <button id="btn-play" class="cyber-btn" disabled>PLAY</button>
            
            <button id="btn-rec" class="cyber-btn">REC START</button>
        </div>

        <div id="rec-indicator">● RECORDING</div>
        <div id="status-log">WAITING FOR INPUT...</div>
    </div>

    <canvas id="canvas"></canvas>

    <script type="module">
        import * as THREE from 'three';
        import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
        import { EffectComposer } from 'three/addons/postprocessing/EffectComposer.js';
        import { RenderPass } from 'three/addons/postprocessing/RenderPass.js';
        import { ShaderPass } from 'three/addons/postprocessing/ShaderPass.js';
        import { GlitchPass } from 'three/addons/postprocessing/GlitchPass.js';
        import { VRMLoaderPlugin, VRMUtils } from '@pixiv/three-vrm';

        // --- UTILS: Logger ---
        const logDiv = document.getElementById('status-log');
        const log = (msg) => { logDiv.innerText = `>> ${msg}`; console.log(msg); };

        // --- 1. SCENE SETUP ---
        const canvas = document.getElementById('canvas');
        const scene = new THREE.Scene();
        scene.background = null; // CSSの砂嵐を見せる

        const camera = new THREE.PerspectiveCamera(30, window.innerWidth / window.innerHeight, 0.1, 100.0);
        camera.position.set(0, 1.2, 4.0);

        const renderer = new THREE.WebGLRenderer({ canvas: canvas, alpha: true, preserveDrawingBuffer: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.setPixelRatio(window.devicePixelRatio);

        // Light
        const dirLight = new THREE.DirectionalLight(0xffffff, 2.0);
        dirLight.position.set(1, 1, 1).normalize();
        scene.add(dirLight);
        const spotLight = new THREE.SpotLight(0x00ffcc, 10.0); // シアンの光
        spotLight.position.set(0, 2, 2);
        scene.add(spotLight);

        // --- 2. CUSTOM SHADER ---
        const HardGlitchShader = {
            uniforms: {
                "tDiffuse": { value: null },
                "time": { value: 0.0 },
                "audioLow": { value: 0.0 },
                "audioHigh": { value: 0.0 }
            },
            vertexShader: `
                varying vec2 vUv;
                void main() {
                    vUv = uv;
                    gl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );
                }
            `,
            fragmentShader: `
                uniform sampler2D tDiffuse;
                uniform float time;
                uniform float audioLow;
                uniform float audioHigh;
                varying vec2 vUv;

                float random(vec2 st) {
                    return fract(sin(dot(st.xy, vec2(12.9898,78.233))) * 43758.5453123);
                }

                void main() {
                    vec2 p = vUv;
                    
                    // MOSH
                    float shake = audioLow * 0.15;
                    if (random(vec2(time, p.y)) < 0.3) {
                        p.x += (random(vec2(time, p.y)) - 0.5) * shake;
                    }

                    // RGB SPLIT
                    float shift = audioHigh * 0.05;
                    vec4 color;
                    color.r = texture2D(tDiffuse, p + vec2(shift, 0.0)).r;
                    color.g = texture2D(tDiffuse, p).g;
                    color.b = texture2D(tDiffuse, p - vec2(shift, 0.0)).b;
                    color.a = texture2D(tDiffuse, p).a;

                    // VOID / DECAY
                    float noiseVal = random(floor(p * 60.0) + time); 
                    float threshold = 0.96 - (audioHigh * 0.9); 

                    if (noiseVal > threshold) {
                        discard;
                    }

                    // INVERT
                    if (audioLow > 0.85 && random(vec2(time, 0.0)) > 0.9) {
                        color.rgb = 1.0 - color.rgb;
                    }

                    gl_FragColor = color;
                }
            `
        };

        const composer = new EffectComposer(renderer);
        composer.addPass(new RenderPass(scene, camera));
        const hardGlitchPass = new ShaderPass(HardGlitchShader);
        composer.addPass(hardGlitchPass);
        const glitchPass = new GlitchPass();
        glitchPass.goWild = false;
        composer.addPass(glitchPass);


        // --- 3. AUDIO FILE SYSTEM ---
        let audioCtx, analyser, dataArray, source;
        let audioEl = new Audio();
        audioEl.loop = true; // ループ再生
        audioEl.crossOrigin = "anonymous";

        const playBtn = document.getElementById('btn-play');

        // Audio Initialization
        function setupAudioContext() {
            if (!audioCtx) {
                audioCtx = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioCtx.createAnalyser();
                analyser.fftSize = 256;
                dataArray = new Uint8Array(analyser.frequencyBinCount);

                // Audio Element Source -> Analyser -> Speaker
                source = audioCtx.createMediaElementSource(audioEl);
                source.connect(analyser);
                analyser.connect(audioCtx.destination); // スピーカーに出力
            }
        }

        // File Upload Handler
        document.getElementById('audio-input').addEventListener('change', (e) => {
            const file = e.target.files[0];
            if (!file) return;

            const url = URL.createObjectURL(file);
            audioEl.src = url;
            
            log("AUDIO LOADED: " + file.name);
            playBtn.disabled = false;
            playBtn.innerText = "PLAY";
        });

        // Play/Pause Handler
        playBtn.addEventListener('click', () => {
            setupAudioContext(); // 初回クリックでContext生成

            if (audioCtx.state === 'suspended') {
                audioCtx.resume();
            }

            if (audioEl.paused) {
                audioEl.play();
                playBtn.innerText = "PAUSE";
                playBtn.classList.add('active');
                log("PLAYING...");
            } else {
                audioEl.pause();
                playBtn.innerText = "PLAY";
                playBtn.classList.remove('active');
                log("PAUSED");
            }
        });


        // --- 4. VRM LOADER ---
        const loader = new GLTFLoader();
        loader.register((parser) => new VRMLoaderPlugin(parser));
        let currentVrm = null;

        function loadVRM(url) {
            loader.load(url, (gltf) => {
                if(currentVrm) {
                    scene.remove(currentVrm.scene);
                    VRMUtils.deepDispose(currentVrm.scene);
                }
                const vrm = gltf.userData.vrm;
                VRMUtils.rotateVRM0(vrm);
                currentVrm = vrm;
                scene.add(vrm.scene);
                
                // Pose
                vrm.humanoid.getNormalizedBoneNode('leftUpperArm').rotation.z = 1.2;
                vrm.humanoid.getNormalizedBoneNode('rightUpperArm').rotation.z = -1.2;
                log("VRM LOADED");
            }, undefined, (e) => log("VRM ERROR"));
        }
        
        // Default VRM
        loadVRM('https://raw.githubusercontent.com/pixiv/three-vrm/master/packages/three-vrm/examples/models/VRM1_Constraint_Twist_Sample.vrm');

        document.getElementById('vrm-input').addEventListener('change', (e) => {
            const file = e.target.files[0];
            if (file) loadVRM(URL.createObjectURL(new Blob([file], { type: "application/octet-stream" })));
        });


        // --- 5. RECORDER ---
        let mediaRecorder;
        let recordedChunks = [];
        const recBtn = document.getElementById('btn-rec');
        const recIndicator = document.getElementById('rec-indicator');

        recBtn.addEventListener('click', () => {
            if (mediaRecorder && mediaRecorder.state === 'recording') stopRecording();
            else startRecording();
        });

        function startRecording() {
            // Canvasの映像 + AudioContextの音声をミックス
            const canvasStream = canvas.captureStream(30);
            
            // 音声があればミックスする
            if (audioCtx && !audioEl.paused) {
                const dest = audioCtx.createMediaStreamDestination();
                // 録画用にもつなぐ
                source.connect(dest); 
                const audioTrack = dest.stream.getAudioTracks()[0];
                canvasStream.addTrack(audioTrack);
            }

            let options = { mimeType: 'video/webm;codecs=vp9' };
            if (!MediaRecorder.isTypeSupported(options.mimeType)) options = { mimeType: 'video/webm' };

            mediaRecorder = new MediaRecorder(canvasStream, options);
            mediaRecorder.ondataavailable = (e) => { if (e.data.size > 0) recordedChunks.push(e.data); };
            mediaRecorder.onstop = () => {
                const blob = new Blob(recordedChunks, { type: 'video/webm' });
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.style.display = 'none';
                a.href = url;
                a.download = 'vj_ritual_' + Date.now() + '.webm';
                document.body.appendChild(a);
                a.click();
                window.URL.revokeObjectURL(url);
                recordedChunks = [];
                log("RECORDING SAVED");
            };

            mediaRecorder.start();
            recBtn.innerText = "REC STOP";
            recBtn.classList.add('active');
            recIndicator.style.display = 'block';
            log("RECORDING...");
        }

        function stopRecording() {
            mediaRecorder.stop();
            recBtn.innerText = "REC START";
            recBtn.classList.remove('active');
            recIndicator.style.display = 'none';
        }


        // --- 6. MAIN LOOP ---
        const clock = new THREE.Clock();

        function animate() {
            requestAnimationFrame(animate);
            const deltaTime = clock.getDelta();
            const time = clock.getElapsedTime();

            let low = 0;
            let high = 0;

            if (analyser && !audioEl.paused) {
                analyser.getByteFrequencyData(dataArray);
                const bassRange = dataArray.slice(0, 15); // Low freq
                const trebleRange = dataArray.slice(100, 200); // High freq
                
                const avg = (arr) => arr.reduce((a, b) => a + b, 0) / arr.length;
                low = avg(bassRange) / 255.0;
                high = avg(trebleRange) / 255.0;
            }

            if (currentVrm) {
                currentVrm.update(deltaTime);
                currentVrm.scene.rotation.y -= (0.005 + (low * 0.08));
                
                const scale = 1.0 + (low * 0.15);
                currentVrm.scene.scale.set(scale, scale, scale);
            }

            hardGlitchPass.uniforms['time'].value = time;
            hardGlitchPass.uniforms['audioLow'].value = low;
            hardGlitchPass.uniforms['audioHigh'].value = high;
            
            glitchPass.enabled = low > 0.85;

            composer.render();
        }

        animate();

        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
            composer.setSize(window.innerWidth, window.innerHeight);
        });
    </script>
</body>
</html>

<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GHOST_PROTOCOL_VJ_V5_LIQUID_WAVE</title>
    <link rel="icon" href="data:,">

    <style>
        /* --- UNDERGROUND STYLING --- */
        body, html {
            margin: 0; padding: 0; width: 100%; height: 100%;
            background-color: #000000; overflow: hidden;
            font-family: 'Courier New', Courier, monospace;
        }

        /* 背景の砂嵐ノイズ */
        .static-noise {
            position: fixed; top: 0; left: 0; width: 100%; height: 100%;
            opacity: 0.15; z-index: 0; pointer-events: none;
            background: url('https://media.giphy.com/media/oEI9uBYSzLpBK/giphy.gif');
            background-size: cover;
            filter: grayscale(100%) contrast(200%);
        }

        #canvas {
            display: block; position: absolute; top: 0; left: 0; z-index: 1;
        }

        /* UI Overlay */
        #ui-layer {
            position: absolute; top: 0; left: 0; width: 100%; height: 100%;
            z-index: 10; pointer-events: none;
            padding: 20px; box-sizing: border-box;
            color: #00ffcc; /* シアンに変更 */
            text-shadow: 0 0 5px #00ffcc;
            background: linear-gradient(to bottom, rgba(0,0,0,0.8) 0%, rgba(0,0,0,0) 30%);
        }

        h1 { 
            font-size: 1.6rem; margin: 0; letter-spacing: 5px; 
            border-bottom: 2px solid #00ffcc; display: inline-block; background: rgba(0,0,0,0.8);
        }

        p { 
            font-size: 0.8rem; margin: 5px 0; background: rgba(0,0,0,0.8); display: inline-block; 
            color: #fff; text-shadow: 0 0 3px #fff;
        }

        /* Controls */
        .controls {
            margin-top: 20px; pointer-events: auto; display: flex; gap: 10px; flex-wrap: wrap;
        }

        .cyber-btn {
            padding: 10px 20px; border: 2px solid #00ffcc; background: #000;
            color: #00ffcc; cursor: pointer; font-weight: bold; font-family: inherit;
            transition: 0.1s; text-transform: uppercase;
            min-width: 120px; text-align: center;
            box-shadow: 0 0 5px rgba(0,255,204,0.3);
        }
        .cyber-btn:hover { background: #00ffcc; color: #000; box-shadow: 0 0 20px #00ffcc;}
        .cyber-btn.active { background: #00ffcc; color: #000; box-shadow: 0 0 25px #00ffcc; }
        .cyber-btn:disabled { opacity: 0.2; cursor: not-allowed; border-color: #555; color: #555; }

        #btn-rec { border-color: #ff0055; color: #ff0055; }
        #btn-rec:hover { background: #ff0055; color: #000; }
        #btn-rec.active { background: #ff0055; color: #fff; box-shadow: 0 0 20px #ff0055; }

        #status-log {
            position: absolute; bottom: 20px; left: 20px; 
            font-size: 0.7rem; color: #fff; white-space: pre;
            background: rgba(0,0,0,0.9); padding: 5px;
            border: 1px dashed #00ffcc;
        }

        #rec-indicator {
            display: none; position: absolute; top: 20px; right: 20px;
            color: #ff0055; font-weight: bold; animation: blinkFast 0.05s infinite;
            background: rgba(0,0,0,0.8); padding: 5px; border: 2px solid #ff0055;
            font-size: 1.4rem;
        }
        @keyframes blinkFast { 0% { opacity: 1; } 50% { opacity: 0.3; } }

        input[type="file"] { display: none; }
    </style>

    <script type="importmap">
    {
        "imports": {
            "three": "https://unpkg.com/three@0.160.0/build/three.module.js",
            "three/addons/": "https://unpkg.com/three@0.160.0/examples/jsm/",
            "@pixiv/three-vrm": "https://unpkg.com/@pixiv/three-vrm@2.1.0/lib/three-vrm.module.js"
        }
    }
    </script>
</head>
<body>
    <div class="static-noise"></div>

    <div id="ui-layer">
        <h1>V5.0: LIQUID_WAVE_PROTOCOL</h1>
        <div>
            <p>>> SENSITIVITY: HYPER (RAW DATA)</p><br>
            <p>>> EFFECT: HEAVY DISTORTION</p>
        </div>

        <div class="controls">
            <input type="file" id="vrm-input" accept=".vrm">
            <label for="vrm-input" class="cyber-btn">1. LOAD VRM</label>
            
            <input type="file" id="audio-input" accept=".mp3, .wav, .flac, .m4a">
            <label for="audio-input" class="cyber-btn">2. LOAD AUDIO</label>

            <button id="btn-play" class="cyber-btn" disabled>PLAY / PAUSE</button>
            
            <button id="btn-rec" class="cyber-btn">REC START</button>
        </div>

        <div id="rec-indicator">!! REC !!</div>
        <div id="status-log">SYSTEM READY.</div>
    </div>

    <canvas id="canvas"></canvas>

    <script type="module">
        import * as THREE from 'three';
        import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
        import { EffectComposer } from 'three/addons/postprocessing/EffectComposer.js';
        import { RenderPass } from 'three/addons/postprocessing/RenderPass.js';
        import { ShaderPass } from 'three/addons/postprocessing/ShaderPass.js';
        import { OutputPass } from 'three/addons/postprocessing/OutputPass.js';
        import { VRMLoaderPlugin, VRMUtils } from '@pixiv/three-vrm';

        const logDiv = document.getElementById('status-log');
        const log = (msg) => { 
            logDiv.innerText = `>> ${msg}\n` + logDiv.innerText.substring(0, 100); 
            console.log(msg); 
        };

        // --- 1. SCENE SETUP ---
        const canvas = document.getElementById('canvas');
        const scene = new THREE.Scene();
        scene.background = null; 

        const camera = new THREE.PerspectiveCamera(45, window.innerWidth / window.innerHeight, 0.1, 100.0);
        camera.position.set(0, 1.3, 2.8); 
        camera.lookAt(0, 1.1, 0);

        const renderer = new THREE.WebGLRenderer({ canvas: canvas, alpha: true, preserveDrawingBuffer: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));

        // Lighting
        const dirLight = new THREE.DirectionalLight(0xffffff, 2.0);
        dirLight.position.set(0, 1, 1).normalize();
        scene.add(dirLight);
        
        const spotLight = new THREE.SpotLight(0x00ffcc, 15.0);
        spotLight.position.set(0, 3, 3);
        scene.add(spotLight);

        // --- 2. LIQUID WAVE SHADER ---
        // アバターを液体のようにぐにゃぐにゃにするシェーダー
        const V5WaveShader = {
            uniforms: {
                "tDiffuse": { value: null },
                "time": { value: 0.0 },
                "audioLow": { value: 0.0 }, 
                "audioMid": { value: 0.0 }, 
                "audioHigh": { value: 0.0 },
                "resolution": { value: new THREE.Vector2() }
            },
            vertexShader: `
                varying vec2 vUv;
                void main() {
                    vUv = uv;
                    gl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );
                }
            `,
            fragmentShader: `
                uniform sampler2D tDiffuse;
                uniform float time;
                uniform float audioLow;
                uniform float audioMid;
                uniform float audioHigh;
                uniform vec2 resolution;
                varying vec2 vUv;

                float random(vec2 st) {
                    return fract(sin(dot(st.xy, vec2(12.9898,78.233))) * 43758.5453123);
                }

                void main() {
                    vec2 p = vUv;
                    
                    // --- 1. HYPER SENSITIVE WAVE (液状化) ---
                    // 低音（Bass）: 大きくゆっくりとしたうねり
                    float waveBass = sin(p.y * 5.0 + time * 10.0) * (audioLow * 0.15); // 感度高め
                    
                    // 高音（High）: 細かく速い振動（ビリビリ）
                    float waveHigh = sin(p.y * 80.0 + time * 50.0) * (audioHigh * 0.03);

                    // 横揺れ適用
                    p.x += waveBass + waveHigh;

                    // 縦揺れ（中音域）
                    p.y += cos(p.x * 10.0 + time * 15.0) * (audioMid * 0.05);


                    // --- 2. SHOCKWAVE (KICK DRUM) ---
                    // 低音が強い時に画面中心から衝撃波
                    if (audioLow > 0.5) {
                        vec2 center = vec2(0.5, 0.5);
                        float dist = distance(p, center);
                        float shock = (1.0 - dist) * audioLow * 0.1;
                        p -= (p - center) * shock; // 中心から外へ広げる
                    }


                    // --- 3. CHROMATIC ABERRATION (色ずれ) ---
                    // 波打つタイミングで色もずらす
                    float shift = (audioLow * 0.05) + (audioHigh * 0.03);
                    vec4 color;
                    
                    // R, G, Bをそれぞれ違う波形でずらして取得
                    color.r = texture2D(tDiffuse, p + vec2(shift, 0.0)).r;
                    color.g = texture2D(tDiffuse, p).g;
                    color.b = texture2D(tDiffuse, p - vec2(shift, 0.0)).b;
                    color.a = texture2D(tDiffuse, p).a;


                    // --- 4. NOISE & SCANLINES ---
                    // アナログTVのようなノイズ
                    float noise = random(p + time) * (audioHigh * 0.3);
                    color.rgb += noise;
                    
                    // スキャンライン
                    color.rgb -= sin(p.y * 800.0) * 0.1;

                    // --- 5. FLASH (STROBE) ---
                    // キックに合わせて明滅
                    if (audioLow > 0.8) {
                        color.rgb += 0.2;
                    }

                    gl_FragColor = color;
                }
            `
        };

        const composer = new EffectComposer(renderer);
        composer.addPass(new RenderPass(scene, camera));
        
        const wavePass = new ShaderPass(V5WaveShader);
        wavePass.uniforms['resolution'].value.set(window.innerWidth, window.innerHeight);
        composer.addPass(wavePass);

        const outputPass = new OutputPass();
        composer.addPass(outputPass);


        // --- 3. AUDIO FILE SYSTEM (HYPER SENSITIVE) ---
        let audioCtx, analyser, dataArray, source;
        let audioEl = new Audio();
        audioEl.loop = true; 
        audioEl.crossOrigin = "anonymous";

        const playBtn = document.getElementById('btn-play');

        function setupAudioContext() {
            if (!audioCtx) {
                audioCtx = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioCtx.createAnalyser();
                analyser.fftSize = 2048; // 最高解像度
                analyser.smoothingTimeConstant = 0.1; // 【重要】平滑化をほぼ無くし、生データに近くする（超敏感）
                dataArray = new Uint8Array(analyser.frequencyBinCount);

                source = audioCtx.createMediaElementSource(audioEl);
                source.connect(analyser);
                analyser.connect(audioCtx.destination); 
            }
        }

        document.getElementById('audio-input').addEventListener('change', (e) => {
            const file = e.target.files[0];
            if (!file) return;
            const url = URL.createObjectURL(file);
            audioEl.src = url;
            log("AUDIO LOADED");
            playBtn.disabled = false;
        });

        playBtn.addEventListener('click', () => {
            setupAudioContext();
            if (audioCtx.state === 'suspended') audioCtx.resume();

            if (audioEl.paused) {
                audioEl.play();
                playBtn.innerText = "PAUSE";
                playBtn.classList.add('active');
            } else {
                audioEl.pause();
                playBtn.innerText = "PLAY";
                playBtn.classList.remove('active');
            }
        });


        // --- 4. VRM LOADER ---
        const loader = new GLTFLoader();
        loader.register((parser) => new VRMLoaderPlugin(parser));
        let currentVrm = null;

        function loadVRM(url) {
            loader.load(url, (gltf) => {
                if(currentVrm) {
                    scene.remove(currentVrm.scene);
                    VRMUtils.deepDispose(currentVrm.scene);
                }
                const vrm = gltf.userData.vrm;
                VRMUtils.rotateVRM0(vrm);
                currentVrm = vrm;
                scene.add(vrm.scene);
                
                vrm.humanoid.getNormalizedBoneNode('leftUpperArm').rotation.z = 1.2;
                vrm.humanoid.getNormalizedBoneNode('rightUpperArm').rotation.z = -1.2;

                log("VRM LOADED");
            }, undefined, (e) => log("VRM ERROR"));
        }
        
        loadVRM('https://raw.githubusercontent.com/pixiv/three-vrm/master/packages/three-vrm/examples/models/VRM1_Constraint_Twist_Sample.vrm');

        document.getElementById('vrm-input').addEventListener('change', (e) => {
            const file = e.target.files[0];
            if (file) loadVRM(URL.createObjectURL(new Blob([file], { type: "application/octet-stream" })));
        });


        // --- 5. RECORDER ---
        let mediaRecorder;
        let recordedChunks = [];
        const recBtn = document.getElementById('btn-rec');
        const recIndicator = document.getElementById('rec-indicator');

        recBtn.addEventListener('click', () => {
            if (mediaRecorder && mediaRecorder.state === 'recording') stopRecording();
            else startRecording();
        });

        function startRecording() {
            const canvasStream = canvas.captureStream(60); 
            if (audioCtx && !audioEl.paused) {
                const dest = audioCtx.createMediaStreamDestination();
                source.connect(dest); 
                canvasStream.addTrack(dest.stream.getAudioTracks()[0]);
            }
            
            let options = { mimeType: 'video/webm;codecs=vp9', videoBitsPerSecond: 8000000 };
            if (!MediaRecorder.isTypeSupported(options.mimeType)) options = { mimeType: 'video/webm' };

            mediaRecorder = new MediaRecorder(canvasStream, options);
            mediaRecorder.ondataavailable = (e) => { if (e.data.size > 0) recordedChunks.push(e.data); };
            mediaRecorder.onstop = () => {
                const blob = new Blob(recordedChunks, { type: 'video/webm' });
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.style.display = 'none';
                a.href = url;
                a.download = 'vj_liquid_' + Date.now() + '.webm';
                document.body.appendChild(a);
                a.click();
                window.URL.revokeObjectURL(url);
                recordedChunks = [];
                log("SAVED.");
            };

            mediaRecorder.start();
            recBtn.innerText = "STOP";
            recBtn.classList.add('active');
            recIndicator.style.display = 'block';
        }

        function stopRecording() {
            mediaRecorder.stop();
            recBtn.innerText = "REC START";
            recBtn.classList.remove('active');
            recIndicator.style.display = 'none';
        }


        // --- 6. LOOP ---
        const clock = new THREE.Clock();

        function animate() {
            requestAnimationFrame(animate);
            const deltaTime = clock.getDelta();
            const time = clock.getElapsedTime();

            let low = 0, mid = 0, high = 0;

            if (analyser && !audioEl.paused) {
                analyser.getByteFrequencyData(dataArray);
                
                const bassData = dataArray.slice(0, 20);
                const midData = dataArray.slice(30, 150);
                const highData = dataArray.slice(150, 400);
                
                const avg = (arr) => arr.length > 0 ? arr.reduce((a, b) => a + b, 0) / arr.length : 0;
                
                // 感度を上げるために値をブースト
                low = Math.min(1.0, (avg(bassData) / 255.0) * 1.2);
                mid = Math.min(1.0, (avg(midData) / 255.0) * 1.2);
                high = Math.min(1.0, (avg(highData) / 255.0) * 1.5); // 高音は特に反応しやすく
            }

            if (currentVrm) {
                currentVrm.update(deltaTime);
                currentVrm.scene.rotation.y += 0.005; // ゆっくり回転
                currentVrm.scene.position.set(0, 0, 0);
                
                // 物理的な拡大縮小も少し大げさに
                const scale = 1.0 + (low * 0.2);
                currentVrm.scene.scale.set(scale, scale, scale);
            }

            wavePass.uniforms['time'].value = time;
            wavePass.uniforms['audioLow'].value = low;
            wavePass.uniforms['audioMid'].value = mid;
            wavePass.uniforms['audioHigh'].value = high;

            composer.render();
        }

        animate();

        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
            composer.setSize(window.innerWidth, window.innerHeight);
            wavePass.uniforms['resolution'].value.set(window.innerWidth, window.innerHeight);
        });
    </script>
</body>
</html>

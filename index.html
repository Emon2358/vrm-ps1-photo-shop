<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GHOST_PROTOCOL_VJ_V4_FIXED</title>
    <link rel="icon" href="data:,">

    <style>
        /* --- UNDERGROUND STYLING --- */
        body, html {
            margin: 0; padding: 0; width: 100%; height: 100%;
            background-color: #000000; overflow: hidden;
            font-family: 'Courier New', Courier, monospace;
        }

        /* 背景の砂嵐ノイズ */
        .static-noise {
            position: fixed; top: 0; left: 0; width: 100%; height: 100%;
            opacity: 0.3; z-index: 0; pointer-events: none;
            background: url('https://media.giphy.com/media/oEI9uBYSzLpBK/giphy.gif');
            background-size: cover;
            filter: grayscale(100%) contrast(300%) brightness(70%);
        }

        #canvas {
            display: block; position: absolute; top: 0; left: 0; z-index: 1;
        }

        /* UI Overlay */
        #ui-layer {
            position: absolute; top: 0; left: 0; width: 100%; height: 100%;
            z-index: 10; pointer-events: none;
            padding: 20px; box-sizing: border-box;
            color: #00ff00;
            text-shadow: 0 0 5px #00ff00;
            background: linear-gradient(to bottom, rgba(0,0,0,0.9) 0%, rgba(0,0,0,0) 25%);
        }

        h1 { 
            font-size: 1.6rem; margin: 0; letter-spacing: 5px; 
            border-bottom: 2px solid #00ff00; display: inline-block; background: rgba(0,0,0,0.8);
        }

        p { 
            font-size: 0.8rem; margin: 5px 0; background: rgba(0,0,0,0.8); display: inline-block; 
            color: #00ffff; text-shadow: 0 0 3px #00ffff;
        }

        /* Controls */
        .controls {
            margin-top: 20px; pointer-events: auto; display: flex; gap: 10px; flex-wrap: wrap;
        }

        .cyber-btn {
            padding: 10px 20px; border: 2px solid #00ff00; background: #000;
            color: #00ff00; cursor: pointer; font-weight: bold; font-family: inherit;
            transition: 0.1s; text-transform: uppercase;
            min-width: 120px; text-align: center;
            box-shadow: 0 0 5px rgba(0,255,0,0.5);
        }
        .cyber-btn:hover { background: #00ff00; color: #000; box-shadow: 0 0 15px #00ff00;}
        .cyber-btn.active { background: #00ff00; color: #fff; box-shadow: 0 0 20px #00ff00; }
        .cyber-btn:disabled { opacity: 0.2; cursor: not-allowed; border-color: #555; color: #555; }

        #btn-rec { border-color: #ff00ff; color: #ff00ff; }
        #btn-rec:hover { background: #ff00ff; color: #000; }
        #btn-rec.active { background: #ff00ff; color: #fff; box-shadow: 0 0 20px #ff00ff; }

        #status-log {
            position: absolute; bottom: 20px; left: 20px; 
            font-size: 0.7rem; color: #fff; white-space: pre;
            background: rgba(0,0,0,0.9); padding: 5px;
            border: 1px dashed #00ffff;
        }

        #rec-indicator {
            display: none; position: absolute; top: 20px; right: 20px;
            color: #ff00ff; font-weight: bold; animation: blinkFast 0.1s infinite;
            background: rgba(0,0,0,0.8); padding: 5px; border: 2px solid #ff00ff;
            font-size: 1.4rem;
        }
        @keyframes blinkFast { 0% { opacity: 1; } 50% { opacity: 0; } }

        input[type="file"] { display: none; }
    </style>

    <script type="importmap">
    {
        "imports": {
            "three": "https://unpkg.com/three@0.160.0/build/three.module.js",
            "three/addons/": "https://unpkg.com/three@0.160.0/examples/jsm/",
            "@pixiv/three-vrm": "https://unpkg.com/@pixiv/three-vrm@2.1.0/lib/three-vrm.module.js"
        }
    }
    </script>
</head>
<body>
    <div class="static-noise"></div>

    <div id="ui-layer">
        <h1>V4.0: DESTRUCTION_PROTOCOL</h1>
        <div>
            <p>>> STATUS: REPAIRED</p><br>
            <p>>> SHADER: COMPILED</p>
        </div>

        <div class="controls">
            <input type="file" id="vrm-input" accept=".vrm">
            <label for="vrm-input" class="cyber-btn">1. LOAD VRM</label>
            
            <input type="file" id="audio-input" accept=".mp3, .wav, .flac, .m4a">
            <label for="audio-input" class="cyber-btn">2. LOAD AUDIO</label>

            <button id="btn-play" class="cyber-btn" disabled>PLAY / PAUSE</button>
            
            <button id="btn-rec" class="cyber-btn">REC START</button>
        </div>

        <div id="rec-indicator">!! REC !!</div>
        <div id="status-log">SYSTEM READY. WAITING FOR INPUT...</div>
    </div>

    <canvas id="canvas"></canvas>

    <script type="module">
        import * as THREE from 'three';
        import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
        import { EffectComposer } from 'three/addons/postprocessing/EffectComposer.js';
        import { RenderPass } from 'three/addons/postprocessing/RenderPass.js';
        import { ShaderPass } from 'three/addons/postprocessing/ShaderPass.js';
        import { OutputPass } from 'three/addons/postprocessing/OutputPass.js';
        import { VRMLoaderPlugin, VRMUtils } from '@pixiv/three-vrm';

        const logDiv = document.getElementById('status-log');
        const log = (msg) => { 
            logDiv.innerText = `>> ${msg}\n` + logDiv.innerText.substring(0, 100); 
            console.log(msg); 
        };

        // --- 1. SCENE SETUP ---
        const canvas = document.getElementById('canvas');
        const scene = new THREE.Scene();
        scene.background = null; 

        const camera = new THREE.PerspectiveCamera(40, window.innerWidth / window.innerHeight, 0.1, 100.0);
        camera.position.set(0, 1.4, 3.0); 
        camera.lookAt(0, 1.0, 0);

        const renderer = new THREE.WebGLRenderer({ canvas: canvas, alpha: true, preserveDrawingBuffer: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));

        const dirLight = new THREE.DirectionalLight(0xffffff, 1.5);
        dirLight.position.set(0.5, 2, 1).normalize();
        scene.add(dirLight);
        
        const cyberRedLight = new THREE.PointLight(0xff0055, 10.0, 10);
        cyberRedLight.position.set(-2, 1.5, 0);
        scene.add(cyberRedLight);

        const cyberBlueLight = new THREE.PointLight(0x00ffff, 10.0, 10);
        cyberBlueLight.position.set(2, 1.5, 0);
        scene.add(cyberBlueLight);

        // --- 2. DESTRUCTION SHADER (FIXED) ---
        const V4DestructionShader = {
            uniforms: {
                "tDiffuse": { value: null },
                "time": { value: 0.0 },
                "audioLow": { value: 0.0 }, 
                "audioMid": { value: 0.0 }, 
                "audioHigh": { value: 0.0 },
                "resolution": { value: new THREE.Vector2(window.innerWidth, window.innerHeight) }
            },
            vertexShader: `
                varying vec2 vUv;
                void main() {
                    vUv = uv;
                    gl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );
                }
            `,
            fragmentShader: `
                uniform sampler2D tDiffuse;
                uniform float time;
                uniform float audioLow;
                uniform float audioMid;
                uniform float audioHigh;
                uniform vec2 resolution;
                varying vec2 vUv;

                // vec2を受け取る乱数関数
                float random(vec2 st) {
                    return fract(sin(dot(st.xy, vec2(12.9898,78.233))) * 43758.5453123);
                }

                void main() {
                    vec2 p = vUv;
                    vec2 coord = vUv * resolution;

                    vec4 finalColor = texture2D(tDiffuse, p);
                    
                    // 1. DATA MOSH GRID (Low)
                    float grid_intensity = audioLow * 0.2;
                    float grid_size = 50.0 + (audioLow * 200.0);
                    vec2 grid_p = floor(p * grid_size) / grid_size;
                    
                    float grid_offset = random(grid_p * time * 5.0) * grid_intensity;
                    p.x += sin(grid_p.y * 10.0 + time * 10.0) * grid_offset;
                    p.y += cos(grid_p.x * 10.0 + time * 10.0) * grid_offset;

                    // 2. SCANLINES & BLUR (Mid)
                    float scanline = sin(p.y * resolution.y * 2.0) * 0.05 + 0.95;
                    finalColor.rgb *= scanline;

                    float blur_amount = audioMid * 0.005;
                    // 簡易ブラー
                    vec4 blurColor = texture2D(tDiffuse, p + vec2(blur_amount, blur_amount)) * 0.25 +
                                     texture2D(tDiffuse, p + vec2(-blur_amount, blur_amount)) * 0.25 +
                                     texture2D(tDiffuse, p + vec2(blur_amount, -blur_amount)) * 0.25 +
                                     texture2D(tDiffuse, p + vec2(-blur_amount, -blur_amount)) * 0.25;
                    
                    finalColor = mix(finalColor, blurColor, audioMid);

                    // 3. COLOR CHANNEL SHIFT & SORT (High)
                    float shift_strength = audioHigh * 0.05;
                    float sort_strength = audioHigh * 0.1;
                    
                    vec4 shiftedColor;
                    shiftedColor.r = texture2D(tDiffuse, p + vec2(shift_strength, 0.0)).r;
                    shiftedColor.g = texture2D(tDiffuse, p + vec2(-shift_strength * 0.5, shift_strength * 0.5)).g;
                    shiftedColor.b = texture2D(tDiffuse, p + vec2(0.0, -shift_strength)).b;
                    shiftedColor.a = texture2D(tDiffuse, p).a;

                    // Pixel Sorting-like effect
                    float sort_noise = random(floor(coord / 10.0) + time);
                    if (sort_noise > 1.0 - sort_strength) {
                        // --- 修正箇所: floatをvec2に変換 ---
                        float seed = floor(p.y * 100.0) + time;
                        float sort_offset = (random(vec2(seed, 0.0)) - 0.5) * sort_strength * 2.0;
                        // --------------------------------
                        shiftedColor = texture2D(tDiffuse, p + vec2(sort_offset, 0.0));
                    }
                    finalColor = mix(finalColor, shiftedColor, 0.7);

                    // 4. HEAVY DIGITAL NOISE
                    float total_loudness = (audioLow + audioMid + audioHigh) / 3.0;
                    float noise_amount = random(p * time + total_loudness * 10.0) * 0.3 * total_loudness;
                    finalColor.rgb += noise_amount;

                    // 5. EDGE HIGHLIGHT
                    float edge_strength = 0.005 + total_loudness * 0.01;
                    vec4 edge_color = texture2D(tDiffuse, p);
                    vec4 dx = texture2D(tDiffuse, p + vec2(edge_strength, 0.0));
                    vec4 dy = texture2D(tDiffuse, p + vec2(0.0, edge_strength));
                    float edge = length(dx.rgb - edge_color.rgb) + length(dy.rgb - edge_color.rgb);
                    finalColor.rgb += edge * (1.0 + total_loudness * 2.0);

                    // 6. Color Invert
                    if (audioLow > 0.6 && audioMid > 0.5 && random(vec2(time, 0.0)) > 0.85) {
                        finalColor.rgb = 1.0 - finalColor.rgb;
                    }

                    gl_FragColor = finalColor;
                }
            `
        };

        const composer = new EffectComposer(renderer);
        composer.addPass(new RenderPass(scene, camera));
        
        const destructionPass = new ShaderPass(V4DestructionShader);
        destructionPass.uniforms['resolution'].value.set(window.innerWidth, window.innerHeight);
        composer.addPass(destructionPass);

        const outputPass = new OutputPass();
        composer.addPass(outputPass);


        // --- 3. AUDIO FILE SYSTEM ---
        let audioCtx, analyser, dataArray, source;
        let audioEl = new Audio();
        audioEl.loop = true; 
        audioEl.crossOrigin = "anonymous";

        const playBtn = document.getElementById('btn-play');

        function setupAudioContext() {
            if (!audioCtx) {
                audioCtx = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioCtx.createAnalyser();
                analyser.fftSize = 1024;
                analyser.smoothingTimeConstant = 0.5;
                dataArray = new Uint8Array(analyser.frequencyBinCount);

                source = audioCtx.createMediaElementSource(audioEl);
                source.connect(analyser);
                analyser.connect(audioCtx.destination); 
            }
        }

        document.getElementById('audio-input').addEventListener('change', (e) => {
            const file = e.target.files[0];
            if (!file) return;
            const url = URL.createObjectURL(file);
            audioEl.src = url;
            log("AUDIO LOADED: " + file.name);
            playBtn.disabled = false;
        });

        playBtn.addEventListener('click', () => {
            setupAudioContext();
            if (audioCtx.state === 'suspended') audioCtx.resume();

            if (audioEl.paused) {
                audioEl.play();
                playBtn.innerText = "PAUSE";
                playBtn.classList.add('active');
            } else {
                audioEl.pause();
                playBtn.innerText = "PLAY";
                playBtn.classList.remove('active');
            }
        });


        // --- 4. VRM LOADER ---
        const loader = new GLTFLoader();
        loader.register((parser) => new VRMLoaderPlugin(parser));
        let currentVrm = null;

        function loadVRM(url) {
            loader.load(url, (gltf) => {
                if(currentVrm) {
                    scene.remove(currentVrm.scene);
                    VRMUtils.deepDispose(currentVrm.scene);
                }
                const vrm = gltf.userData.vrm;
                VRMUtils.rotateVRM0(vrm);
                currentVrm = vrm;
                scene.add(vrm.scene);
                
                vrm.humanoid.getNormalizedBoneNode('leftUpperArm').rotation.z = 0.5;
                vrm.humanoid.getNormalizedBoneNode('rightUpperArm').rotation.z = -0.5;
                vrm.humanoid.getNormalizedBoneNode('spine').rotation.x = 0.1;

                log("VRM LOADED.");
            }, undefined, (e) => log("VRM ERROR: " + e));
        }
        
        loadVRM('https://raw.githubusercontent.com/pixiv/three-vrm/master/packages/three-vrm/examples/models/VRM1_Constraint_Twist_Sample.vrm');

        document.getElementById('vrm-input').addEventListener('change', (e) => {
            const file = e.target.files[0];
            if (file) loadVRM(URL.createObjectURL(new Blob([file], { type: "application/octet-stream" })));
        });


        // --- 5. RECORDER ---
        let mediaRecorder;
        let recordedChunks = [];
        const recBtn = document.getElementById('btn-rec');
        const recIndicator = document.getElementById('rec-indicator');

        recBtn.addEventListener('click', () => {
            if (mediaRecorder && mediaRecorder.state === 'recording') stopRecording();
            else startRecording();
        });

        function startRecording() {
            const canvasStream = canvas.captureStream(60); 
            if (audioCtx && !audioEl.paused) {
                const dest = audioCtx.createMediaStreamDestination();
                source.connect(dest); 
                canvasStream.addTrack(dest.stream.getAudioTracks()[0]);
            }
            
            let options = { mimeType: 'video/webm;codecs=vp9', videoBitsPerSecond: 8000000 };
            if (!MediaRecorder.isTypeSupported(options.mimeType)) options = { mimeType: 'video/webm' };

            mediaRecorder = new MediaRecorder(canvasStream, options);
            mediaRecorder.ondataavailable = (e) => { if (e.data.size > 0) recordedChunks.push(e.data); };
            mediaRecorder.onstop = () => {
                const blob = new Blob(recordedChunks, { type: 'video/webm' });
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.style.display = 'none';
                a.href = url;
                a.download = 'vj_fix_' + Date.now() + '.webm';
                document.body.appendChild(a);
                a.click();
                window.URL.revokeObjectURL(url);
                recordedChunks = [];
                log("SAVED.");
            };

            mediaRecorder.start();
            recBtn.innerText = "STOP";
            recBtn.classList.add('active');
            recIndicator.style.display = 'block';
        }

        function stopRecording() {
            mediaRecorder.stop();
            recBtn.innerText = "REC START";
            recBtn.classList.remove('active');
            recIndicator.style.display = 'none';
        }


        // --- 6. LOOP ---
        const clock = new THREE.Clock();

        function animate() {
            requestAnimationFrame(animate);
            const deltaTime = clock.getDelta();
            const time = clock.getElapsedTime();

            let low = 0, mid = 0, high = 0;

            if (analyser && !audioEl.paused) {
                analyser.getByteFrequencyData(dataArray);
                
                const bassData = dataArray.slice(0, 30);
                const midData = dataArray.slice(30, 200);
                const highData = dataArray.slice(200, 500);
                
                const avg = (arr) => arr.length > 0 ? arr.reduce((a, b) => a + b, 0) / arr.length : 0;
                
                low = avg(bassData) / 255.0;
                mid = avg(midData) / 255.0;
                high = avg(highData) / 255.0;
            }

            if (currentVrm) {
                currentVrm.update(deltaTime);
                currentVrm.scene.rotation.y += 0.005; 
                currentVrm.scene.position.set(0, 0, 0);
                const breath = 1.0 + Math.sin(time * 2.0) * 0.01 + (low * 0.05);
                currentVrm.scene.scale.set(breath, breath, breath);
            }

            destructionPass.uniforms['time'].value = time;
            destructionPass.uniforms['audioLow'].value = low;
            destructionPass.uniforms['audioMid'].value = mid;
            destructionPass.uniforms['audioHigh'].value = high;

            composer.render();
        }

        animate();

        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
            composer.setSize(window.innerWidth, window.innerHeight);
            destructionPass.uniforms['resolution'].value.set(window.innerWidth, window.innerHeight);
        });
    </script>
</body>
</html>

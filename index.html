<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>nihonkokumin_VJ_V5_EROSION</title>
    <link rel="icon" href="data:,">

    <style>
        /* --- UNDERGROUND STYLING --- */
        body, html {
            margin: 0; padding: 0; width: 100%; height: 100%;
            background-color: #000; overflow: hidden;
            font-family: 'Courier New', Courier, monospace;
        }

        /* 背景の砂嵐ノイズ (アバターが消えた時に見える) */
        .static-noise {
            position: fixed; top: 0; left: 0; width: 100%; height: 100%;
            opacity: 0.25; /* 少し濃くして視認性を高める */
            z-index: 0; pointer-events: none;
            background: url('https://media.giphy.com/media/oEI9uBYSzLpBK/giphy.gif');
            background-size: cover;
        }

        #canvas {
            display: block; position: absolute; top: 0; left: 0; z-index: 1;
            transform: translateZ(0);
            transition: transform 0.05s ease-out;
        }
        .screen-shake {
            transform: translate3d(var(--shake-x, 0), var(--shake-y, 0), 0);
        }

        /* UI Overlay */
        #ui-layer {
            position: absolute; top: 0; left: 0; width: 100%; height: 100%;
            z-index: 10; pointer-events: none;
            padding: 20px; box-sizing: border-box;
            color: #ff9900; /* 警告色：黄土/オレンジ */
            text-shadow: 2px 2px 0px #000, 0 0 8px #ff9900; 
        }

        h1 { 
            font-size: 1.6rem; margin: 0; letter-spacing: 4px; 
            border-bottom: 3px solid #ff9900; display: inline-block; background: #000;
        }
        p { font-size: 0.9rem; margin: 5px 0; background: #000; display: inline-block;}

        /* Controls */
        .controls {
            margin-top: 20px; pointer-events: auto; display: flex; gap: 10px; flex-wrap: wrap;
        }

        .cyber-btn {
            padding: 12px 22px; border: 2px solid #ff9900; background: #000;
            color: #ff9900; cursor: pointer; font-weight: bold; font-family: inherit;
            transition: 0.1s; text-transform: uppercase;
            min-width: 130px; text-align: center;
            box-shadow: 0 0 5px rgba(255, 153, 0, 0.5); 
        }
        .cyber-btn:hover { background: #ff9900; color: #000; box-shadow: 0 0 15px #ff9900; }
        .cyber-btn.active { background: #ff9900; color: #fff; box-shadow: 0 0 20px #ff9900; }
        .cyber-btn:disabled { opacity: 0.3; cursor: not-allowed; border-color: #555; color: #555; box-shadow: none; }

        /* 録画ボタンは赤くする */
        #btn-rec { border-color: #ff004c; color: #ff004c; box-shadow: 0 0 5px rgba(255, 0, 76, 0.5);}
        #btn-rec:hover { background: #ff004c; color: #000; box-shadow: 0 0 15px #ff004c; }
        #btn-rec.active { background: #ff004c; color: #fff; box-shadow: 0 0 20px #ff004c; }

        #status-log {
            position: absolute; bottom: 20px; left: 20px; 
            font-size: 0.8rem; color: #fff; white-space: pre;
            text-shadow: none; 
        }

        /* 録画中インジケーター */
        #rec-indicator {
            display: none; position: absolute; top: 20px; right: 20px;
            color: yellow; font-weight: bold; animation: blink 0.5s infinite;
            background: #000; padding: 8px; border: 2px solid yellow;
            text-shadow: 0 0 8px yellow;
        }
        @keyframes blink { 50% { opacity: 0; } }

        input[type="file"] { display: none; }
    </style>

    <script type="importmap">
    {
        "imports": {
            "three": "https://unpkg.com/three@0.160.0/build/three.module.js",
            "three/addons/": "https://unpkg.com/three@0.160.0/examples/jsm/",
            "@pixiv/three-vrm": "https://unpkg.com/@pixiv/three-vrm@2.1.0/lib/three-vrm.module.js"
        }
    }
    </script>
</head>
<body>
    <div class="static-noise"></div>

    <div id="ui-layer">
        <h1>V5.0: EXISTENCE_EROSION</h1>
        <div>
            <p>>> WARNING: SUBTLE_DESTRUCTION</p><br>
            <p>>> PROTOCOL: DIGITAL_DECAY</p>
        </div>

        <div class="controls">
            <input type="file" id="vrm-input" accept=".vrm">
            <label for="vrm-input" class="cyber-btn">1. LOAD VRM</label>
            
            <input type="file" id="audio-input" accept=".mp3, .wav, .flac, .m4a">
            <label for="audio-input" class="cyber-btn">2. LOAD AUDIO</label>

            <button id="btn-play" class="cyber-btn" disabled>PLAY</button>
            
            <button id="btn-rec" class="cyber-btn">REC START</button>
        </div>

        <div id="rec-indicator">● RECORDING</div>
        <div id="status-log">SYSTEM_IDLE: AWAITING COMMANDS...</div>
    </div>

    <canvas id="canvas"></canvas>

    <script type="module">
        import * as THREE from 'three';
        import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
        import { EffectComposer } from 'three/addons/postprocessing/EffectComposer.js';
        import { RenderPass } from 'three/addons/postprocessing/RenderPass.js';
        import { ShaderPass } from 'three/addons/postprocessing/ShaderPass.js';
        import { VRMLoaderPlugin, VRMUtils } from '@pixiv/three-vrm';

        // --- UTILS: Logger ---
        const logDiv = document.getElementById('status-log');
        const log = (msg) => { logDiv.innerText = `>> ${msg}`; console.log(msg); };

        // --- 1. SCENE SETUP ---
        const canvas = document.getElementById('canvas');
        const scene = new THREE.Scene();
        scene.background = null; 

        const camera = new THREE.PerspectiveCamera(30, window.innerWidth / window.innerHeight, 0.1, 100.0);
        camera.position.set(0, 1.2, 4.0);

        const renderer = new THREE.WebGLRenderer({ canvas: canvas, alpha: true, preserveDrawingBuffer: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.setPixelRatio(window.devicePixelRatio);

        // Light (アバターの視認性を確保しつつ、攻撃的な演出)
        const dirLight = new THREE.DirectionalLight(0xff9900, 3.0); // オレンジ系のライト
        dirLight.position.set(1, 1, 1).normalize();
        scene.add(dirLight);
        const spotLight = new THREE.SpotLight(0x00ffff, 15.0); // シアンのスポット
        spotLight.position.set(0, 2, 2);
        spotLight.angle = Math.PI / 6;
        spotLight.penumbra = 0.5;
        scene.add(spotLight);
        
        const ambientLight = new THREE.AmbientLight(0xffffff, 0.7); // 明るめの環境光でアバターの視認性を確保
        scene.add(ambientLight);


        // --- 2. EXISTENCE_EROSION SHADER (VISUALLY AGGRESSIVE BUT VISIBLE) ---
        const ExistenceErosionShader = {
            uniforms: {
                "tDiffuse": { value: null },
                "time": { value: 0.0 },
                "audioLow": { value: 0.0 },
                "audioMid": { value: 0.0 },
                "audioHigh": { value: 0.0 },
                "resolution": { value: new THREE.Vector2() }
            },
            vertexShader: `
                varying vec2 vUv;
                void main() {
                    vUv = uv;
                    gl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );
                }
            `,
            fragmentShader: `
                uniform sampler2D tDiffuse;
                uniform float time;
                uniform float audioLow;
                uniform float audioMid;
                uniform float audioHigh;
                uniform vec2 resolution;
                varying vec2 vUv;

                float random(vec2 st) {
                    return fract(sin(dot(st.xy, vec2(12.9898,78.233))) * 43758.5453123);
                }

                // グリッド状ノイズ (ハーフドーン/ディザリング風)
                float grid(vec2 st, float res) {
                    return smoothstep(0.0, 0.5, abs(sin(st.x * res)) + abs(sin(st.y * res)));
                }

                void main() {
                    vec2 p = vUv;
                    vec2 coord = gl_FragCoord.xy / resolution.xy;

                    // 1. ノイズフロート / 画面揺れ (全体の音量に反応)
                    float noiseFloatStrength = (audioLow + audioMid + audioHigh) / 3.0 * 0.005;
                    p += (random(vec2(time * 10.0, p.y * 10.0)) - 0.5) * noiseFloatStrength;

                    // 2. クロマティックアベレーション強化 (より激しく)
                    float colorShiftAmount = (audioLow + audioMid + audioHigh) / 3.0 * 0.1;
                    vec4 color;
                    color.r = texture2D(tDiffuse, p + vec2(colorShiftAmount, 0.0)).r;
                    color.g = texture2D(tDiffuse, p).g;
                    color.b = texture2D(tDiffuse, p - vec2(colorShiftAmount, 0.0)).b;
                    color.a = texture2D(tDiffuse, p).a;

                    // 3. デジタルディザリング / ハーフドーン化 (中域の音に強く反応)
                    float ditherFactor = audioMid * 5.0 + audioHigh * 3.0; // 音が大きいほどディザが強くなる
                    float ditherValue = grid(coord, 10.0 + ditherFactor * 50.0); // グリッド密度を変化
                    color.rgb *= (0.5 + 0.5 * ditherValue); // グリッド状に色を減衰

                    // 4. エッジ強調 & エッジノイズ (アバターの輪郭を攻撃的に)
                    float edgeStrength = audioLow * 0.005;
                    vec4 centralColor = texture2D(tDiffuse, p);
                    vec4 upColor = texture2D(tDiffuse, p + vec2(0.0, 1.0/resolution.y) * edgeStrength * 10.0);
                    vec4 downColor = texture2D(tDiffuse, p - vec2(0.0, 1.0/resolution.y) * edgeStrength * 10.0);
                    vec4 leftColor = texture2D(tDiffuse, p + vec2(1.0/resolution.x, 0.0) * edgeStrength * 10.0);
                    vec4 rightColor = texture2D(tDiffuse, p - vec2(1.0/resolution.x, 0.0) * edgeStrength * 10.0);

                    float edgeDetect = length(centralColor.rgb - upColor.rgb) + 
                                       length(centralColor.rgb - downColor.rgb) +
                                       length(centralColor.rgb - leftColor.rgb) + 
                                       length(centralColor.rgb - rightColor.rgb);
                    
                    if (edgeDetect > 0.1 && centralColor.a > 0.5) { // アバターのエッジで
                        color.rgb = mix(color.rgb, vec3(1.0, 0.5, 0.0), edgeDetect * (0.5 + audioHigh * 0.5)); // オレンジ系のエッジ
                        if (random(vec2(time * 20.0, p.y * 100.0)) > (0.8 - audioHigh * 0.2)) { // エッジがノイズで荒れる
                            color.rgb = mix(color.rgb, vec3(random(p.xy)), 0.3);
                        }
                    }

                    // 5. 内部スキャンライン / スライス (低音のピーク時)
                    float scanline = sin(p.y * 100.0 + time * 50.0) * 0.5 + 0.5;
                    if (audioLow > 0.8 && centralColor.a > 0.5) { // アバター内部のみ
                        color.rgb = mix(color.rgb, vec3(scanline), 0.3); // スキャンラインを混ぜる
                        if (random(vec2(time * 5.0, p.y)) > 0.9) { // 不定期なスライス
                            color.rgb = mix(color.rgb, vec3(0.0), audioLow * 0.5); // 部分的に黒く消える
                        }
                    }

                    // 6. ボクセル化 / 部分破壊 (高音の強ピークで一瞬)
                    if (audioHigh > 0.9 && random(vec2(time * 50.0, 0.0)) > 0.5) {
                        vec2 voxelCoord = floor(p * 20.0) / 20.0; // 粗いピクセルブロック
                        color = texture2D(tDiffuse, voxelCoord);
                        if (random(voxelCoord + time) > 0.8) { // ランダムにブロックを消失
                            discard;
                        }
                    }

                    // 7. 色相シフト / 反転 (全体の音量に反応)
                    float hueShift = (audioLow + audioMid + audioHigh) / 3.0 * 2.0;
                    vec3 hsv = rgb2hsv(color.rgb);
                    hsv.x = fract(hsv.x + hueShift * 0.1); // 色相をゆっくりシフト
                    color.rgb = hsv2rgb(hsv);

                    if (audioLow > 0.95 && random(vec2(time * 50.0, 0.0)) > 0.8) {
                        color.rgb = 1.0 - color.rgb; // 強低音で色反転
                    }
                    if (audioHigh > 0.9 && random(vec2(time * 50.0, 0.0)) > 0.8) {
                        color.rgb = 1.0 - color.rgb; // 強高音で色反転
                    }


                    gl_FragColor = color;
                }

                // RGB to HSV, HSV to RGB functions (for hue shift)
                vec3 rgb2hsv(vec3 c) {
                    vec4 K = vec4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0);
                    vec4 p = mix(vec4(c.bg, K.wz), vec4(c.gb, K.xy), step(c.b, c.g));
                    vec4 q = mix(vec4(p.xyw, c.r), vec4(c.r, p.yzx), step(p.x, c.r));
                    float d = q.x - min(q.w, q.y);
                    float e = 1.0e-10;
                    return vec3(abs(q.z + (q.w - q.y) / (6.0 * d + e)), d / (q.x + e), q.x);
                }
                vec3 hsv2rgb(vec3 c) {
                    vec4 K = vec4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0);
                    vec3 p = abs(fract(c.xxx + K.xyz) * 6.0 - K.w);
                    return c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);
                }
            `
        };

        const composer = new EffectComposer(renderer);
        composer.addPass(new RenderPass(scene, camera));
        
        const existenceErosionPass = new ShaderPass(ExistenceErosionShader);
        composer.addPass(existenceErosionPass);
        

        // --- 3. AUDIO FILE SYSTEM ---
        let audioCtx, analyser, dataArray, source;
        let audioEl = new Audio();
        audioEl.loop = true;
        audioEl.crossOrigin = "anonymous";

        const playBtn = document.getElementById('btn-play');

        function setupAudioContext() {
            if (!audioCtx) {
                audioCtx = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioCtx.createAnalyser();
                analyser.fftSize = 2048;
                dataArray = new Uint8Array(analyser.frequencyBinCount);

                source = audioCtx.createMediaElementSource(audioEl);
                source.connect(analyser);
                analyser.connect(audioCtx.destination);
            }
        }

        document.getElementById('audio-input').addEventListener('change', (e) => {
            const file = e.target.files[0];
            if (!file) return;

            const url = URL.createObjectURL(file);
            audioEl.src = url;
            
            log(`AUDIO LOADED: ${file.name}`);
            playBtn.disabled = false;
            playBtn.innerText = "PLAY";
        });

        playBtn.addEventListener('click', () => {
            setupAudioContext();

            if (audioCtx.state === 'suspended') {
                audioCtx.resume();
            }

            if (audioEl.paused) {
                audioEl.play();
                playBtn.innerText = "PAUSE";
                playBtn.classList.add('active');
                log("PLAYING...");
            } else {
                audioEl.pause();
                playBtn.innerText = "PLAY";
                playBtn.classList.remove('active');
                log("PAUSED");
            }
        });


        // --- 4. VRM LOADER ---
        const loader = new GLTFLoader();
        loader.register((parser) => new VRMLoaderPlugin(parser));
        let currentVrm = null;

        function loadVRM(url) {
            loader.load(url, (gltf) => {
                if(currentVrm) {
                    scene.remove(currentVrm.scene);
                    VRMUtils.deepDispose(currentVrm.scene);
                }
                const vrm = gltf.userData.vrm;
                VRMUtils.rotateVRM0(vrm);
                currentVrm = vrm;
                scene.add(vrm.scene);
                
                vrm.humanoid.getNormalizedBoneNode('leftUpperArm').rotation.z = 1.2;
                vrm.humanoid.getNormalizedBoneNode('rightUpperArm').rotation.z = -1.2;
                log("VRM LOADED");
            }, undefined, (e) => log("VRM ERROR"));
        }
        
        loadVRM('https://raw.githubusercontent.com/pixiv/three-vrm/master/packages/three-vrm/examples/models/VRM1_Constraint_Twist_Sample.vrm');

        document.getElementById('vrm-input').addEventListener('change', (e) => {
            const file = e.target.files[0];
            if (file) loadVRM(URL.createObjectURL(new Blob([file], { type: "application/octet-stream" })));
        });


        // --- 5. RECORDER ---
        let mediaRecorder;
        let recordedChunks = [];
        const recBtn = document.getElementById('btn-rec');
        const recIndicator = document.getElementById('rec-indicator');

        recBtn.addEventListener('click', () => {
            if (mediaRecorder && mediaRecorder.state === 'recording') stopRecording();
            else startRecording();
        });

        function startRecording() {
            const canvasStream = renderer.domElement.captureStream(30);
            
            if (audioCtx && !audioEl.paused) {
                const dest = audioCtx.createMediaStreamDestination();
                source.connect(dest); 
                const audioTrack = dest.stream.getAudioTracks()[0];
                canvasStream.addTrack(audioTrack);
            }

            let options = { mimeType: 'video/webm;codecs=vp9' };
            if (!MediaRecorder.isTypeSupported(options.mimeType)) options = { mimeType: 'video/webm' };

            mediaRecorder = new MediaRecorder(canvasStream, options);
            mediaRecorder.ondataavailable = (e) => { if (e.data.size > 0) recordedChunks.push(e.data); };
            mediaRecorder.onstop = () => {
                const blob = new Blob(recordedChunks, { type: 'video/webm' });
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.style.display = 'none';
                a.href = url;
                a.download = 'vj_existence_erosion_' + Date.now() + '.webm';
                document.body.appendChild(a);
                a.click();
                window.URL.revokeObjectURL(url);
                recordedChunks = [];
                log("RECORDING SAVED");
            };

            mediaRecorder.start();
            recBtn.innerText = "REC STOP";
            recBtn.classList.add('active');
            recIndicator.style.display = 'block';
            log("RECORDING IN PROGRESS...");
        }

        function stopRecording() {
            mediaRecorder.stop();
            recBtn.innerText = "REC START";
            recBtn.classList.remove('active');
            recIndicator.style.display = 'none';
        }


        // --- 6. MAIN LOOP ---
        const clock = new THREE.Clock();

        function animate() {
            requestAnimationFrame(animate);
            const deltaTime = clock.getDelta();
            const time = clock.getElapsedTime();

            let low = 0; 
            let mid = 0; 
            let high = 0; 

            if (analyser && !audioEl.paused) {
                analyser.getByteFrequencyData(dataArray);
                
                const bassRange = dataArray.slice(0, 15);
                const midRange = dataArray.slice(30, 80);
                const trebleRange = dataArray.slice(100, 200);
                
                const avg = (arr) => arr.reduce((a, b) => a + b, 0) / arr.length;
                low = avg(bassRange) / 255.0;
                mid = avg(midRange) / 255.0;
                high = avg(trebleRange) / 255.0;
            }

            // VRM Update (回転速度・拡大縮小)
            if (currentVrm) {
                currentVrm.update(deltaTime);
                currentVrm.scene.rotation.y -= (0.005 + (low * 0.1) + (mid * 0.05));
                
                const scale = 1.0 + (low * 0.1); 
                currentVrm.scene.scale.set(scale, scale, scale);
            }

            // Shader Uniforms Update
            existenceErosionPass.uniforms['time'].value = time;
            existenceErosionPass.uniforms['audioLow'].value = low;
            existenceErosionPass.uniforms['audioMid'].value = mid;
            existenceErosionPass.uniforms['audioHigh'].value = high;
            existenceErosionPass.uniforms['resolution'].value.set(window.innerWidth, window.innerHeight);

            // 画面振動 (Screen Shake)
            if (low > 0.8 || high > 0.8) {
                const shakeIntensity = Math.max(low, high);
                const shakeX = (Math.random() - 0.5) * shakeIntensity * 10;
                const shakeY = (Math.random() - 0.5) * shakeIntensity * 10;
                canvas.style.setProperty('--shake-x', `${shakeX}px`);
                canvas.style.setProperty('--shake-y', `${shakeY}px`);
                canvas.classList.add('screen-shake');
            } else {
                canvas.classList.remove('screen-shake');
            }

            // スポットライトの点滅 (高音のピークで激しく)
            spotLight.intensity = (high > 0.7) ? (15.0 + Math.random() * 10.0) : 15.0;
            spotLight.color.setHex((high > 0.7 && Math.random() > 0.5) ? 0xff004c : 0x00ffff); // 赤とシアンが入れ替わる

            // 環境光の点滅 (低音のピークで激しく)
            ambientLight.intensity = (low > 0.8) ? (0.7 + Math.random() * 0.3) : 0.7;


            composer.render();
        }

        animate();

        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
            composer.setSize(window.innerWidth, window.innerHeight);
        });
    </script>
</body>
</html>
